# AI論文調査 2026-01-18

## 調査トピック
LLM（大規模言語モデル）

## 論文リスト

### ★★★ 重要

- **[Recursive Language Models](https://arxiv.org/abs/2512.24601)** - Alex L. Zhang, Tim Kraska, Omar Khattab (MIT CSAIL)
  - LLMが自身を再帰的に呼び出すことで、コンテキストウィンドウの100倍以上の入力を処理可能にする推論戦略。CodeQAでベースモデル24%→RLM 62%と大幅改善

- **[Engram: Conditional Memory via Scalable Lookup](https://arxiv.org/abs/2601.07372)** - Peking University, DeepSeek-AI
  - Transformerに条件付きメモリ（O(1)ルックアップ）を追加する新しいスパース性の軸。MoEベースラインを上回り、長文脈検索が84.2→97.0に向上

- **[SimpleMem: Efficient Lifelong Memory for LLM Agents](https://arxiv.org/abs/2601.02553)** - Jiaqi Liu et al.
  - LLMエージェントの長期記憶を効率化するフレームワーク。トークン消費を最大30分の1に削減しつつF1スコア26.4%向上

### ★★ 注目

- **[MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents](https://arxiv.org/abs/2511.11793)** - MiroThinker Team
  - 強化学習によるツール拡張推論エージェント。256Kコンテキストで最大600回のツール呼び出しが可能。GAIA benchmarkで81.9%達成

- **[Challenges and Research Directions for Large Language Model Inference Hardware](https://arxiv.org/abs/2601.05047)** - Xiaoyu Ma, David Patterson (Google)
  - LLM推論ハードウェアの課題と研究方向性。メモリ帯域・容量・インターコネクト遅延がボトルネックであることを指摘

- **[LTX-2: Efficient Joint Audio-Visual Foundation Model](https://arxiv.org/abs/2601.03233)** - Lightricks
  - 19Bパラメータのオーディオ・ビジュアル統合生成モデル。双方向クロスアテンションで同期した映像・音声を生成

- **[STEP3-VL-10B Technical Report](https://arxiv.org/abs/2601.09668)** - StepFun
  - 10Bパラメータで10-20倍大きいモデルに匹敵するマルチモーダルVLM。MMBench 92.05%、MMMU 80.11%達成

### ★ 参考

- **[Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management](https://arxiv.org/abs/2601.01885)** -
  - LLMエージェントの長期・短期記憶を統合管理するフレームワークの提案

- **[Continuum Memory Architectures for Long-Horizon LLM Agents](https://arxiv.org/abs/2601.09913)** -
  - 長期的なタスクを処理するLLMエージェント向けの連続的メモリアーキテクチャ

## 所感

2026年1月の論文動向として、以下の傾向が見られる：

1. **長文脈処理の進化**: Recursive Language Models (RLM) やEngramなど、コンテキストウィンドウの制限を克服するアプローチが活発。特にRLMの「LLMが自分自身を再帰的に呼び出す」という発想は、2026年のパラダイムとして注目される

2. **エージェント記憶システムの成熟**: SimpleMem、Agentic Memory、Continuum Memoryなど、LLMエージェントの記憶管理に関する研究が多い。効率性と性能のバランスが重要視されている

3. **推論効率の追求**: Google Patterson氏のハードウェア論文が示すように、推論コストの削減が経済的に重要な課題として認識されている

4. **小型モデルの高性能化**: STEP3-VL-10Bが示すように、10B規模でも適切な訓練で100B級モデルに匹敵する性能を実現可能に

調査日: 2026-01-18
